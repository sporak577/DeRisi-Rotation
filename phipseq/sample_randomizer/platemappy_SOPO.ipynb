{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03927927",
   "metadata": {},
   "source": [
    "Here I am using Haleigh Miller's platemappy code but adjusted it to my BWF cohort. \n",
    "\n",
    "Authors: ChatGPT and Sophie Porak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da7d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import random \n",
    "import numpy as np \n",
    "import math \n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"\n",
    "    Split list 'lst' into n (as even as possible) chunks. \n",
    "    Returns a list of lists with length n. Some may differ by max 1 element.\n",
    "\n",
    "    This function ensures that data gets split into chunks/groups as evenly as possible! \n",
    "    \"\"\"\n",
    "    n = max(1, n)\n",
    "    q, r = divmod(len(lst), n) #returns quotient and remainder e.g. divmod(5, 2) = (2, 1), as 2 x 2 + 1 = 5\n",
    "    out = []\n",
    "    start = 0\n",
    "    for i in range(n):\n",
    "        size = q + (1 if i < r else 0)\n",
    "        out.append(lst[start:start+size])\n",
    "        start += size \n",
    "    return out\n",
    "\n",
    "\n",
    "class Metadata:\n",
    "    \"\"\"\n",
    "    Plate map generator that support any number of sample groups.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    X : pd.DataFrame. \n",
    "        This is the metadata table. Index must be unique sample IDs (strings).\n",
    "\n",
    "    group_col : str\n",
    "        Column that holds the category label for each sample.\n",
    "        Examples: 'History of BWF' 'Incident F1' 'control' etc.\n",
    "\n",
    "    n_ag : int\n",
    "        Number of AG controls per plate\n",
    "\n",
    "    n_canary : int \n",
    "        Number of Canary control wells per plate\n",
    "\n",
    "    n_mAb : int \n",
    "        Count of mAb controls per plate.\n",
    "\n",
    "    duplicate_ : int \n",
    "        Number of technical duplicates per sample (e.g. 2 means duplicates for each sample)\n",
    "\n",
    "    block_ : int, default 0\n",
    "        Size of a contriguous block of wells to insert (filled with 'HC')\n",
    "    \n",
    "    block_column_ : list[int], default []\n",
    "        Zero-based column indices to block entirely (0..11). Blockers filled with 0. \n",
    "    \n",
    "    block_row_ : list[int], default []\n",
    "        Zero-based row indices to block entirely (0..7). Blockers filled with 0. \n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    k : int\n",
    "        Number of plates\n",
    "    \n",
    "    cats : list[str]\n",
    "        Ordered list of unique group labels found in X[group_col]\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            X : pd.DataFrame, \n",
    "            group_col: str, \n",
    "            n_ag: int, \n",
    "            n_canary: int, \n",
    "            n_mAb: int, \n",
    "            duplicate_: int, \n",
    "            block_ = 0, \n",
    "            block_column_ = None, \n",
    "            block_row_ = None, \n",
    "    ) -> None: \n",
    "        if block_column_ is None: block_column_ = []\n",
    "        if block_row_ is None: block_row_ = []\n",
    "\n",
    "        assert X.index.is_unique, \"X.index (sample IDs) must be unique.\"\n",
    "        assert group_col in X.columns, f\"{group_col} not in X.columns\"\n",
    "\n",
    "        self._X = X.copy()\n",
    "        self._group = group_col \n",
    "        self._ag = int(n_ag)\n",
    "        self._can = int(n_canary)\n",
    "        self._mab = int(n_mAb)\n",
    "        self._block = int(block_)\n",
    "        self._dup = int(duplicate_)\n",
    "        self._blockcol = list(block_column_)\n",
    "        self._blockrow = list(block_row_)\n",
    "\n",
    "        #categories (groups) present in metadata \n",
    "        self.cats = list(self._X[self._group].astype(str).unique())\n",
    "\n",
    "        self.k = self._init_params()\n",
    "\n",
    "    def _init_params(self) -> int:\n",
    "        \"\"\"\n",
    "        Compute the number of plates given controls + blocks.\n",
    "        \"\"\"\n",
    "        x = (\n",
    "            self._ag + self._can + self._mab\n",
    "            + self._block \n",
    "            + 12 * len(self._blockcol)\n",
    "            + 12 * len(self._blockrow)\n",
    "        )\n",
    "\n",
    "        usable = max(0, 96 - x) #forces result to be at least 1\n",
    "        total_samples = self._X.shape[0] * (self._dup if self._dup else 1)\n",
    "        #the idea is to find out how many plates you need to hold all of your samples including the above considerations.\n",
    "        k = math.ceil(total_samples / usable) if usable else math.ceil(total_samples / 1) #math.ceil rounds number up to nearest integer. e.g. math.ceil(4.2) = 5. in this case ensures there are enough slots / wells.\n",
    "        return max(1, k) #forces result to be at least 1\n",
    "    \n",
    "    # ------- Allocation Method -----\n",
    "\n",
    "    def allocate_samples_to_plate(self) -> dict: #arrow indicates that this function is expected to return a dictionary\n",
    "        \"\"\"\n",
    "        Distribute samples to plates while preserving per-group balance. \n",
    "        Strategy: for each group, shuffle the samples and then split into k chunks(so number of plates) as even as possible. \n",
    "        then mix these chunks across plates. \n",
    "        \"\"\"\n",
    "        #generates number from 0 up to self.k - 1 and shifts number to start at 1 instead at 0 (with i + 1). each key maps to an empty list. so if you have e.g. 3 plates, then \n",
    "        #you would have 1, 2, 3 mapping to (for now) empty lists. Samples will then be appended to the corresponding list later. \n",
    "        samples_to_plates = {i + 1: [] for i in range(self.k)}\n",
    "\n",
    "        #Built list of samples for each group (with duplication if requested)\n",
    "        for group in self.cats:\n",
    "            samples_g = self._X.index[self._X['self._group'] == group].tolist()\n",
    "            if self._dup and self._dup > 1: \n",
    "                #duplicate each sample self._dup times \n",
    "                samples_g = [s for s in samples_g for _ in range(self._dup)] \n",
    "            \n",
    "            random.shuffle(samples_g)\n",
    "            split = chunks(samples_g, self.k) #list of length k, where samples from each group get distributed across number of plates k as evenly as possible. \n",
    "            for i in range(self.k):\n",
    "                samples_to_plates[i + 1].extend(split[i]) #extend differs from append, as it takes an iterable such as another list and adds each element individually. flattens one level. needed as we start off with an empty list.  \n",
    "\n",
    "        #a final suffle per plate to intermix groups more   \n",
    "        for i in range(self.k):\n",
    "            random.shuffle(samples_to_plates[i + 1])\n",
    "        \n",
    "        return samples_to_plates\n",
    "\n",
    "    def allocate_samples_alt(self) -> dict: \n",
    "        \"\"\"\n",
    "        Alternative allocator: round-robin assignment across plates per group. \n",
    "        \"\"\"\n",
    "        samples_to_plates = {i + 1: [] for i in range(self.k)} #again, creating empty lists as values to each key (plate number)\n",
    "\n",
    "        #for each group, shuffle and then place items round-robin by plate\n",
    "        for group in self.cats:\n",
    "            samples_g = self._X.index[self._X[self._group] == group].tolist()\n",
    "            if self._dup and self._dup > 1: \n",
    "                samples_g = [s for s in samples_g for _ in range(self._dup)]\n",
    "            random.shuffle(samples_g)\n",
    "\n",
    "            plate_idx = 0\n",
    "            for s in samples_g:\n",
    "                samples_to_plates[plate_idx + 1].append(s) # to each plate, append the randomly shuffled samples of each group. \n",
    "                plate_idx = (plate_idx + 1) % self.k #moves it to next plate. % self.k wraps it around when you reach the last plate. Because 3 / 3 = 1 with remainder 0. for 2 / 3, 3 fits zero times but the remainder is 2. \n",
    "\n",
    "\n",
    "        #Optional shuffle\n",
    "        for i in range(self.k):\n",
    "            random.shuffle(samples_to_plates[i+1])\n",
    "        \n",
    "        return samples_to_plates\n",
    "\n",
    "    def create_plates(self, samples_to_plates: dict) -> dict: \n",
    "        \"\"\"\n",
    "        Creates plate matrices (8 x 12) with sample IDs and controls. \n",
    "        Returns dict: {plate_number: np.ndarray shape (8,12)}\n",
    "        \"\"\"\n",
    "        plates = {}\n",
    "\n",
    "        for i in range(1, self.k + 1):\n",
    "            # Make a fresh list so we don't mutate the input dict\n",
    "            samples = list(samples_to_plates[i])\n",
    "\n",
    "            #build controls fresh for each plate\n",
    "            AG = ['AG'] * self._ag\n",
    "            Canary = ['Canary'] * self._can\n",
    "            mAb = ['mAb'] * self._mab\n",
    "\n",
    "            pool = samples + AG + Canary + mAb \n",
    "            random.shuffle(pool)\n",
    "\n",
    "            #Add contiguous block of 'HC' if requested \n",
    "            if self._block > 0: \n",
    "                #choose an insert start index such that block fits into 96 slots / wells\n",
    "                insert_loc = random.randint(0, max(0, 96 - self._block))\n",
    "\n",
    "                #make a list of 'HC' of length self._block\n",
    "                block_vals = ['HC'] * self._block\n",
    "\n",
    "                #splice the block into pool at position insert_loc. Splicing inserts a sequence into a list at a particular index. doesn't overwrite anything but shifts existing elements to the right. \n",
    "                #python interprets [insert_loc:insert_loc] as \"insert here\".\n",
    "                pool[insert_loc:insert_loc] = block_vals\n",
    "\n",
    "            #Entire blocked rows filled with 0 \n",
    "            for r in sorted(self._blockrow):\n",
    "                insert_loc = r * 12\n",
    "                pool[insert_loc:insert_loc] = [0] * 12\n",
    "\n",
    "            #Entire blocked columns filled with 0 \n",
    "            for c in sorted(self._blockcol):\n",
    "                for rr in range(7, -1, -1): #row index, going from bottom (7) to top (0). inserting higher indices first prevents shifting the lower ones. \n",
    "                    insert_loc = rr * 12 + c #gives the correct flat index. so the location in 96 wp with one single index. \n",
    "                    pool[insert_loc:insert_loc] = [0] #inserts a zero at exactly that location\n",
    "\n",
    "            #pad to 96 to ensure every pool is exactly 96 elements long. \n",
    "            if len(pool) < 96:\n",
    "                pool.extend([0] * (96 - len(pool))) # pad with zeros \n",
    "            if len(pool) > 96: #chops off the extras from the end so you are back to exaactly 96\n",
    "                pool = pool[:96]\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3a28e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phage_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
